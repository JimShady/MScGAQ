---
title: "Space-time practical"
output: html_document
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_file ="space_time_practical.html") }) 
---

## Introduction

In personal monitoring campaigns data often needs to be combined from multiple measurement devices into one consolidated dataset before it can be analysed. In today's practical we are going to combine some data from 'person 81' of the DeMIST study that Shannon Lim is working on at the moment. The datasets are from:

* A microaeth (measures black carbon)
* A GPS device (measures location)

Once we have combined them we will make a table summarising the results, graphs to visualise it, and a short animated GIF showing the persons movement and exposure.

## Set-up

```{r, warning=FALSE, message=FALSE}
rm(list = ls())

library(tidyverse,  quietly = T)
library(sf,         quietly = T)
library(lubridate,  quietly = T)
library(devtools,   quietly = T)
library(gganimate,  quietly = T)
library(gifski,     quietly = T)
library(transformr, quietly= T)

```

## Method

### Data import

First we import the PM2.5 data from the sidepak.

```{r, warning=FALSE, message=FALSE}

black_carbon_data   <- read_csv('https://raw.githubusercontent.com/JimShady/MScGAQ/master/data/black_carbon.csv')

head(black_carbon_data)

```

Then we import the location data from the GPS

```{r, warning=FALSE, message=FALSE}

location_data <- read_csv('https://raw.githubusercontent.com/JimShady/MScGAQ/master/data/gps.csv')

head(location_data)

```

### Data processing

Note that under the column headings for both the `black_carbon_data` and the `location_data`, that the column wih the date and time in has been impored as `chr` which stands for `character`. It basically means that the data type of this column has been set to be text. Actually, we want it to be a date and time data type (known as `POSIXct` in R). Spend a few minutes [googling](www.google.co.uk) what POSIXct is, read some of the results, and make sure you understand what 'the epoch' is in relation to POSIXct. Once you have done that, [write a sentence in this form with your answer](https://goo.gl/forms/V1nyofjVHoDCOn0z2)

Once you have done that, we are going to need to tell R that the data that it thinks is text, is actually POSIXct data. First we'll do the `black_carbon_data`.

```{r, warning=FALSE, message=FALSE}

black_carbon_data$date <- as.POSIXct(black_carbon_data$date, format = '%d/%m/%Y %H:%M')

```

Note the bit of the text above (`format = '%d/%m/%Y %H:%M'`) which tells R the format of the date and time that has been used. By telling R this, it allows it to understand that the text is actually date and time, and converts it to a POSIXct format. We can check it has worked by doing something like this

```{r, warning=FALSE, message=FALSE}

class(black_carbon_data$date)

```

The `location_data` has the date and time formatted a little differently. Can you figure out how to sort it out? It'll be something like the below. [Write your answer into the form ](https://goo.gl/forms/V1nyofjVHoDCOn0z2).

```{r, eval=F}

location_data$date    <- as.POSIXct(location_data$date, format = 'SOMETHING IN HERE')

```

```{r, echo=F}
location_data$date    <- as.POSIXct(location_data$date, format = '%y-%m-%d %H:%M')
```

Our data is now ready to be joined together. As I've said before, there are many ways of doing things in R. I like to use the `dplyr` package to join data together. The code to do so is like this:

```{r, warning=FALSE, message=FALSE}

exposure_dataset     <- left_join(location_data, black_carbon_data, by = c("date" = "date"))

head(exposure_dataset)

```

It's odd that there is no latitude and longitude data shown there. Perhaps it's just the top of the file that is empty? Maybe the GPS was only turned on a few minutes after the microaeth? Figure out how to count how many rows of the data _do_ have GPS data ([google is your friend](https://www.google.com/search?q=count+nas+in+column+r&rlz=1C1GGRV_enGB803GB803&oq=count+nas+in+column+r)). Once you've done that, [write your answer into the form, and push submit](https://goo.gl/forms/V1nyofjVHoDCOn0z2)

We can now remove the data we don't need, as it's been combined into a new dataset called `exposure_dataset`.

```{r, warning=FALSE, message=FALSE}
rm(black_carbon_data)
rm(location_data)
```

Finally, we want to turn this data into a spatial dataset that can be plotted on a map.

```{r, warning=FALSE, message=FALSE}
exposure_dataset <- st_as_sf(exposure_dataset, coords = c('longitude', 'latitude'), crs = 4326, na.fail=F)
```

## Results

### Exposure graph

We now use ggplot2 to plot the `black_carbon` exposure data out.

```{r, warning=FALSE, message=FALSE}

ggplot(exposure_dataset, aes(date, black_carbon)) + 
  geom_path() +
  ggtitle('DeMIST participant 81')

```

As we can see, it looks like there has been some instrument error during the campaign. A black carbon measurement of -50, and another of of 90 look like errors to me. Can you figure out how to recreate the plot, but without data that is under -5, and over 25 I suggest you use the `filter` command from the `dplyr` package. An example of how to use it is `filter(starwars, hair_color == "none" & eye_color == "black")`. If you manage it, you will end up with a graph that looks like this:

```{r, echo=F,warning=FALSE, message=FALSE}
ggplot(filter(exposure_dataset, black_carbon > -5 & black_carbon < 25), aes(date, black_carbon)) + 
  geom_path() +
  ggtitle('DeMIST participant 81')
```

### Table

Let's make a summary table of the particopants mean exposure per hour of the day (combining all the days together). To do that we need to tell R that we are only interested in the hour part of the POSIXct column, and then aggregate by it.

```{r}

hourly_summary <- aggregate(data = exposure_dataset,
                            black_carbon ~ hour(date),
                            FUN=mean)

hourly_summary

```

### Map

We can make a basic map like this (similar to how we did in the [exposure practical](https://jimshady.github.io/MScGAQ/exposure_practical.html) last week):

```{r}

ggplot(exposure_dataset) +
  geom_sf(aes(colour = black_carbon), size=1, alpha = 0.4) +
  scale_colour_distiller(palette = "Spectral") +
  theme(panel.background = element_rect(fill = 'black'),
        panel.grid       = element_blank())

```

It's nice to see the data on a map, but this doesn't really tell us very much other than the study participant did alot of driving. How about using the `filter` command to only plot the concentrations that are greater than 5 perhaps? See if you can figure out how to do that.

### Animated map

Let's see if we can make an animated map now. There's a new package called `gganimate` which makes this quite easy. Note the last few lines of the code below

```{r, fig.height=5, fig.width=3, fig.align = "center"}

my_animation <- ggplot(exposure_dataset) +
                 geom_sf(aes(colour = black_carbon, size = black_carbon), show.legend = F) +
                 labs(title = 'Date & time: {frame_time}') +
                 scale_colour_distiller(palette = "Spectral") +
                 theme(panel.background = element_rect(fill = 'black'),
                        panel.grid       = element_blank()) +
                 transition_time(date) +  # Up until here it was normal ggplot2 code,
                 ease_aes('linear')       # but this is the animation bit

animate(my_animation, fps = 10, duration = 30, renderer = gifski_renderer(file = 'my_animation.gif', loop = TRUE)) # output our animation

```

Although this animated map looks really cool, it doesn't really add to our understanding of the data. It is presented here more as a proof of concept. With some tweaking you could for example have the points coloured white, except when the concentrations were above 10, and then they turn red? A map of the UK could also be put in the background? Being able to communicate your data and 'bring it to life' can be a great way to engage with non-technical audiences also.

## The End.
